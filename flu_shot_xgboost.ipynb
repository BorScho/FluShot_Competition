{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26707, 35), (26708, 35))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the csv-files and take the respondent_id column as index:\n",
    "\n",
    "X_train_df = pd.read_csv(\"training_set_features.csv\", index_col=\"respondent_id\")\n",
    "y_train_df = pd.read_csv(\"training_set_labels.csv\", index_col=\"respondent_id\")\n",
    "X_test_df = pd.read_csv(\"test_set_features.csv\", index_col=\"respondent_id\")\n",
    "\n",
    "X_train_df.shape, X_test_df.shape\n",
    "# Output:\n",
    "# ((26707, 36), (26708, 36))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 11\n",
    "test_size = 0.2\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X_train_df, y_train_df, test_size=test_size, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the two independent binary labels to a categorial output:\n",
    "\n",
    "label_number_to_categories = { 0: \"not vaccinated\", 1: \"only seasonal\", 2 : \"only h1n1\", 3 : \"seasonal and h1n1\"}\n",
    "label_number_to_multilabel = { 0: [0,0], 1: [0,1], 2 : [1,0], 3 : [1,1] }\n",
    "\n",
    "def multiLableTocategory(l):\n",
    "    if np.array_equal(l, [0,0]):\n",
    "        return 0\n",
    "    if np.array_equal(l,[0,1]):\n",
    "        return 1\n",
    "    if np.array_equal(l, [1,0]):\n",
    "        return 2\n",
    "    if np.array_equal(l, [1,1]):\n",
    "        return 3\n",
    "\n",
    "y_train_cat = [ multiLableTocategory(yt) for yt in y_train.values]\n",
    "y_eval_cat = [multiLableTocategory(yt) for yt in y_eval.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = X_train_df.columns[X_train_df.dtypes != \"object\"].values\n",
    "non_numeric_columns = X_train_df.columns[X_train_df.dtypes == \"object\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepro pipeline:\n",
    "\n",
    "numeric_preprocessing_pipeline = Pipeline([\n",
    "    (\"simple_imputer\", SimpleImputer(strategy=\"constant\", fill_value=np.NaN))\n",
    "])\n",
    "\n",
    "\n",
    "# column transformer with only numerical columns:\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        (\"numeric\", numeric_preprocessing_pipeline, num_cols),\n",
    "        (\"ohe_num\", OneHotEncoder(), num_cols),\n",
    "        (\"ohe_non_num\", OneHotEncoder(), non_numeric_columns)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "xbg_clf = XGBClassifier(use_label_encoder=False)\n",
    "#multi_estimator_rdf= MultiOutputClassifier(estimator=xbg_clf)\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"xgb_classifier\", xbg_clf),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:53:57] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('simple_imputer',\n",
       "                                                                   SimpleImputer(fill_value=nan,\n",
       "                                                                                 strategy='constant'))]),\n",
       "                                                  array(['h1n1_concern', 'h1n1_knowledge', 'behavioral_antiviral_meds',\n",
       "       'behavioral_avoidance', 'behavioral_face_mask',\n",
       "       'behavioral_wash_hands', 'behavioral_large_gatherings',\n",
       "       'behavioral_outside_h...\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=6, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=24, num_parallel_tree=1,\n",
       "                               objective='multi:softprob', predictor='auto',\n",
       "                               random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                               scale_pos_weight=None, subsample=1,\n",
       "                               tree_method='exact', use_label_encoder=False,\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipeline.fit(X_train, y_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6988019468363909"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = full_pipeline.predict(X_eval) # predict_proba ?\n",
    "accuracy_score(y_eval_cat, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xgboost.sklearn.XGBClassifier"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf = full_pipeline[\"xgb_classifier\"]\n",
    "type(xgb_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation of dmlc XGBoost / py-xgboost(?)\n",
    "\n",
    "https://xgboost.readthedocs.io/en/stable/python/python_intro.html#setting-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf.get_params()\n",
    "\n",
    "# output:\n",
    "#{'objective': 'multi:softprob',\n",
    "# 'use_label_encoder': False,\n",
    "# 'base_score': 0.5,\n",
    "# 'booster': 'gbtree',\n",
    "# 'colsample_bylevel': 1,\n",
    "# 'colsample_bynode': 1,\n",
    "# 'colsample_bytree': 1,\n",
    "# 'enable_categorical': False,\n",
    "# 'gamma': 0,\n",
    "# 'gpu_id': -1,\n",
    "# 'importance_type': None,\n",
    "# 'interaction_constraints': '',\n",
    "# 'learning_rate': 0.300000012,\n",
    "# 'max_delta_step': 0,\n",
    "# 'max_depth': 6,\n",
    "# 'min_child_weight': 1,\n",
    "# 'missing': nan,\n",
    "# 'monotone_constraints': '()',\n",
    "# 'n_estimators': 100,\n",
    "# 'n_jobs': 24,\n",
    "# 'num_parallel_tree': 1,\n",
    "# 'predictor': 'auto',\n",
    "# 'random_state': 0,\n",
    "# 'reg_alpha': 0,\n",
    "# 'reg_lambda': 1,\n",
    "# 'scale_pos_weight': None,\n",
    "# 'subsample': 1,\n",
    "# 'tree_method': 'exact',\n",
    "# 'validate_parameters': 1,\n",
    "# 'verbosity': None}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('condaPytorchEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df61620949cb14e55b843831dad5e2bfed0f7347786fc0c0d43a7e8bd69fd61c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
